# Thesis_Coding: A Comparative Performance of Hybrid Deep Learning Models for  Stock Price Forecasting
This research examines and compares the performance and training time of Hybrid Deep Learning Models, including RNN, LSTM, and GRU. These models are implemented using two architectures: Stacked Layers and Cascaded Neural Networks, for forecasting stock closing prices. Including the study of the impact of changing the sequencing of models within the Hybrid model to assess differences in forecasting performance for both the short-term (7 days) and the long-term (30 days). The dataset consists of stock prices from five industries, selecting three stocks from volatility levels (Beta), resulting in a total of 15 datasets. The findings indicate that Stacked Layers and Cascaded Neural Networks perform similarly in both short-term and long-term forecasts, with no significant differences in accuracy. However, in terms of training time, Stacked Layers require significantly less time than Cascaded Neural Networks, making them more efficient and resource-saving. Additionally, rearranging the order of models in hybrid architecture does not significantly affect forecasting performance.  Overall, the results suggest that Stacked Layers are the better approach for building Hybrid Deep Learning Models, as they provide similar accuracy while being more efficient in terms of computation and resource usage, making them preferable for both short-term and long-term stock price forecasting.
